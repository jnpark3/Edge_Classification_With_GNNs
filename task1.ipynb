{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import Dataset  # not the one from PyG!\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "\n",
    "from torch_geometric.nn import NNConv\n",
    "from torch.nn.functional import relu, binary_cross_entropy_with_logits, linear\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MyDataset class for handling file loading\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path: Path):\n",
    "        super().__init__()\n",
    "        self.graphs = list(path.glob(\"*.pt\"))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.load(self.graphs[idx])\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs in set: 1000\n",
      "Set of keys in each graph ['y', 'edge_attr', 'x', 'edge_index']\n",
      "Number of nodes in first graph: 419\n",
      "Number of edges in first graph: 4882\n",
      "Number of node features: 6\n",
      "Number of edge features: 4\n",
      "Is this graph undirected?  False\n",
      "Number of edge features: tensor([1., 1., 1.,  ..., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Load first batch (batch_1_0)\n",
    "\n",
    "dataset = MyDataset(Path(\"./dataset/batch_1_0\"))\n",
    "\n",
    "# Preliminary analysis of dataset behavior\n",
    "\n",
    "print(\"Number of graphs in set:\", len(dataset))\n",
    "print(\"Set of keys in each graph\", dataset[0].keys)\n",
    "print(\"Number of nodes in first graph:\", dataset[0].num_nodes)\n",
    "print(\"Number of edges in first graph:\", dataset[0].num_edges)\n",
    "print(\"Number of node features:\", dataset[0].num_node_features)\n",
    "print(\"Number of edge features:\", dataset[0].num_edge_features)\n",
    "print(\"Is this graph undirected? \", dataset[0].is_undirected())\n",
    "\n",
    "print(\"Number of edge features:\", dataset[0]['y'])\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, sample, hidden_layers = [8]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = []\n",
    "        self.linear_weights = torch.randn(2 * sample.num_node_features + sample.num_edge_features)\n",
    "\n",
    "        if len(hidden_layers) == 0:\n",
    "            # Case when no hidden layers are passed\n",
    "            self.conv.append(NNConv(sample.num_node_features, 1))\n",
    "\n",
    "        else:\n",
    "            # Case when hidden layers are passed\n",
    "            self.conv.append(NNConv(sample.num_node_features, hidden_layers[0]))\n",
    "            for i in range(len(hidden_layers) - 1):\n",
    "                self.conv.append(NNConv(hidden_layers[i], hidden_layers[i + 1]))    \n",
    "            self.conv.append(NNConv(hidden_layers[-1], 1))\n",
    "        \n",
    "        self.conv_module = torch.nn.ModuleList(self.conv)\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        x, edge_attr, edge_index = data.x, data.edge_attr, data.edge_index\n",
    "        '''\n",
    "        # Concatenate the edge attributes with the source node attributes\n",
    "        src_node_attrs = x[edge_index[0]]\n",
    "        conv_attributes = torch.cat((edge_attr, src_node_attrs), dim=1)    \n",
    "        '''\n",
    "    \n",
    "        for i in range(len(self.conv)):\n",
    "            print(i)\n",
    "            x = self.conv[i](x, edge_index)\n",
    "            if i < len(self.conv) - 1:\n",
    "                x = relu(x)\n",
    "\n",
    "        edge_scores = x\n",
    "\n",
    "        return edge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.1659, -0.5007,  0.0702, -0.1897,  0.2928,  0.0033],\n",
      "        [ 0.4252, -0.5678,  0.0354,  0.2101, -0.0033, -0.0868],\n",
      "        [ 0.4376, -0.5528,  0.4751, -0.1392,  0.1291,  0.4739],\n",
      "        [-0.1299, -0.4134,  0.0688,  0.2079, -0.6376,  0.1041],\n",
      "        [-0.0148, -0.1922, -0.2920,  0.5942, -0.1580,  0.0997],\n",
      "        [ 0.3732,  0.2799, -0.0902,  0.1668,  0.2739,  0.2050],\n",
      "        [-0.5363, -0.1634,  0.2978,  0.2573,  0.2937, -0.3660],\n",
      "        [ 0.5720,  0.1038, -0.0672,  0.4645, -0.5442,  0.3502]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([0.], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.3674,  0.2895, -0.3118,  0.7534,  0.1908, -0.3774, -0.2028, -0.1939]],\n",
      "       requires_grad=True)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "GNN.forward() missing 2 required positional arguments: 'edge_attr' and 'edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m200\u001b[39m):\n\u001b[1;32m      9\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m     out \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     11\u001b[0m     loss \u001b[39m=\u001b[39m binary_cross_entropy_with_logits(out, data\u001b[39m.\u001b[39my)\n\u001b[1;32m     12\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/Forward-Forward/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: GNN.forward() missing 2 required positional arguments: 'edge_attr' and 'edge_index'"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model = GNN(dataset[0]).to(device)\n",
    "data = dataset[0].to(device)\n",
    "print(list(model.parameters()))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = binary_cross_entropy_with_logits(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "649588312d4cf9672288d95fa805e14ed1c14f756baea9d0a14e0f27f774ca24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
