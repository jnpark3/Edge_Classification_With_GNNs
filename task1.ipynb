{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import Dataset  # not the one from PyG!\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn.functional import relu, binary_cross_entropy_with_logits, linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MyDataset class for handling file loading\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path: Path):\n",
    "        super().__init__()\n",
    "        self.graphs = list(path.glob(\"*.pt\"))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.load(self.graphs[idx])\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs in set: 1000\n",
      "Set of keys in each graph ['y', 'edge_attr', 'x', 'edge_index']\n",
      "Number of nodes in first graph: 419\n",
      "Number of edges in first graph: 4882\n",
      "Number of node features: 6\n",
      "Number of edge features: 4\n",
      "Is this graph undirected?  False\n",
      "Number of edge features: tensor([1., 1., 1.,  ..., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Load first batch (batch_1_0)\n",
    "\n",
    "dataset = MyDataset(Path(\"./dataset/batch_1_0\"))\n",
    "\n",
    "# Preliminary analysis of dataset behavior\n",
    "\n",
    "print(\"Number of graphs in set:\", len(dataset))\n",
    "print(\"Set of keys in each graph\", dataset[0].keys)\n",
    "print(\"Number of nodes in first graph:\", dataset[0].num_nodes)\n",
    "print(\"Number of edges in first graph:\", dataset[0].num_edges)\n",
    "print(\"Number of node features:\", dataset[0].num_node_features)\n",
    "print(\"Number of edge features:\", dataset[0].num_edge_features)\n",
    "print(\"Is this graph undirected? \", dataset[0].is_undirected())\n",
    "\n",
    "print(\"Number of edge features:\", dataset[0]['y'])\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, sample, hidden_layers = [8]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = []\n",
    "\n",
    "        if len(hidden_layers) == 0:\n",
    "            # Case when no hidden layers are passed\n",
    "            self.conv.append(GCNConv(sample.num_node_features, 1))\n",
    "\n",
    "        else:\n",
    "            # Case when hidden layers are passed\n",
    "            self.conv.append(GCNConv(sample.num_node_features, hidden_layers[0]))\n",
    "            for i in range(len(hidden_layers) - 1):\n",
    "                self.conv.append(GCNConv(hidden_layers[i], hidden_layers[i + 1]))    \n",
    "            self.conv.append(GCNConv(hidden_layers[-1], 1))\n",
    "        \n",
    "        self.conv_module = torch.nn.ModuleList(self.conv)\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        x, edge_attr, edge_index = data.x, data.edge_attr, data.edge_index\n",
    "        '''\n",
    "        # Concatenate the edge attributes with the source node attributes\n",
    "        src_node_attrs = x[edge_index[0]]\n",
    "        conv_attributes = torch.cat((edge_attr, src_node_attrs), dim=1)    \n",
    "        '''\n",
    "    \n",
    "        for i in range(len(self.conv)):\n",
    "            print(i)\n",
    "            print(len(x))\n",
    "            print(len(edge_index[0]))\n",
    "            print(len(edge_attr))\n",
    "            x = self.conv[i](x, edge_index, edge_attr)\n",
    "            if i < len(self.conv) - 1:\n",
    "                x = relu(x)\n",
    "        \n",
    "        print(\"Wow\")\n",
    "        edge_inputs = torch.cat([x[edge_index[0]], x[edge_index[1]], edge_attr], dim=1)\n",
    "        edge_scores = linear(edge_inputs, out_channels=1).squeeze()\n",
    "\n",
    "        return edge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.3662,  0.6250, -0.1496, -0.2941,  0.3087,  0.1807],\n",
      "        [ 0.4392, -0.0926, -0.4628, -0.6398,  0.2015,  0.2732],\n",
      "        [-0.5728,  0.0389, -0.0252, -0.4467, -0.4094, -0.3001],\n",
      "        [ 0.4804, -0.0504, -0.4206, -0.2922,  0.2959, -0.6482],\n",
      "        [ 0.6135, -0.1331,  0.1454, -0.0187, -0.4434, -0.3983],\n",
      "        [ 0.0069, -0.1619, -0.1289, -0.6223,  0.5372, -0.5946],\n",
      "        [ 0.1501,  0.0037, -0.4213, -0.2938,  0.0634, -0.5762],\n",
      "        [-0.2775,  0.2389,  0.2953, -0.5232,  0.3022,  0.4491]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([0.], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1917, -0.4653, -0.4165, -0.0752, -0.3142, -0.3794, -0.5647, -0.6712]],\n",
      "       requires_grad=True)]\n",
      "0\n",
      "tensor([[  0.0778,   0.7999,  -1.4975,  -3.6513, -10.3963,   7.5592],\n",
      "        [  0.0810,   0.8275,  -1.5025,  -3.6144, -10.5768,   6.3697],\n",
      "        [  0.0776,   0.8251,  -1.5025,  -3.6569, -10.9876,   6.7283],\n",
      "        ...,\n",
      "        [  0.0739,   0.7932,   1.5025,   3.7059, -10.7744,   8.1863],\n",
      "        [  0.0759,   0.8031,   1.5025,   3.6787, -10.7279,   7.6367],\n",
      "        [  0.0641,   0.8172,   1.5025,   3.8488, -13.1072,   8.4823]])\n",
      "tensor([[  0,   0,   2,  ..., 417, 418, 415],\n",
      "        [ 12,  18,  13,  ..., 407, 408, 409]])\n",
      "tensor([[-1.0220e-02, -4.8168e-04,  2.0000e-01,  2.9313e-03],\n",
      "        [-9.9724e-03, -6.0424e-04,  1.9500e-01,  3.0032e-03],\n",
      "        [-9.8437e-03, -6.8992e-04,  2.0000e-01,  7.5345e-03],\n",
      "        ...,\n",
      "        [-1.0219e-02,  9.5600e-04, -2.0000e-01,  3.4394e-03],\n",
      "        [-8.3340e-03,  8.2881e-04, -2.0000e-01,  4.3215e-03],\n",
      "        [-7.9177e-03, -1.8533e-04, -2.0450e-01,  2.7011e-03]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (21204) must match the size of tensor b (5301) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m200\u001b[39m):\n\u001b[1;32m      9\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m     out \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     11\u001b[0m     loss \u001b[39m=\u001b[39m binary_cross_entropy_with_logits(out, data\u001b[39m.\u001b[39my)\n\u001b[1;32m     12\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/Forward-Forward/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[69], line 34\u001b[0m, in \u001b[0;36mGNN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mprint\u001b[39m(edge_index)\n\u001b[1;32m     33\u001b[0m \u001b[39mprint\u001b[39m(edge_attr)\n\u001b[0;32m---> 34\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv[i](x, edge_index, edge_attr)\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     36\u001b[0m     x \u001b[39m=\u001b[39m relu(x)\n",
      "File \u001b[0;32m~/Desktop/Forward-Forward/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Forward-Forward/myenv/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:198\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    195\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(x)\n\u001b[1;32m    197\u001b[0m \u001b[39m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, edge_weight\u001b[39m=\u001b[39;49medge_weight,\n\u001b[1;32m    199\u001b[0m                      size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     out \u001b[39m=\u001b[39m out \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n",
      "File \u001b[0;32m~/Desktop/Forward-Forward/myenv/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:437\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m         msg_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[0;32m--> 437\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessage(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmsg_kwargs)\n\u001b[1;32m    438\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    439\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[0;32m~/Desktop/Forward-Forward/myenv/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:207\u001b[0m, in \u001b[0;36mGCNConv.message\u001b[0;34m(self, x_j, edge_weight)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmessage\u001b[39m(\u001b[39mself\u001b[39m, x_j: Tensor, edge_weight: OptTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mreturn\u001b[39;00m x_j \u001b[39mif\u001b[39;00m edge_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m edge_weight\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m) \u001b[39m*\u001b[39;49m x_j\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (21204) must match the size of tensor b (5301) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model = GNN(dataset[0]).to(device)\n",
    "data = dataset[0].to(device)\n",
    "print(list(model.parameters()))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = binary_cross_entropy_with_logits(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "649588312d4cf9672288d95fa805e14ed1c14f756baea9d0a14e0f27f774ca24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
